plot_start_end = function(df,var,name){
var1 = paste(var,"start",sep="_")
var2 = paste(var,"end",sep="_")
df_reshaped = gather(df[c(var1,var2)],"Période","value")
df_reshaped$Période[df_reshaped$Période==var1] ="Début de carrière"
df_reshaped$Période[df_reshaped$Période==var2] ="Fin de carrière"
ggplot(df_reshaped,aes(value,fill=Période)) +
geom_density(alpha=.5) +
xlab(name) +  ylab("Densité")
}
diff_start_end = function(var,df, scaled= FALSE,prop=FALSE,p=FALSE){
var1 = paste(var,"start",sep="_")
var2 = paste(var,"end",sep="_")
start = unlist(df[var1])
end = unlist(df[var2])
if(p){return(t.test(start,end)$p.value %>% format.pval(digits=2,eps = .001))
}else if(prop){
return(mean(end < start))
}else if(scaled){
return((mean(end)-mean(start))/sd(c(start,end)))
}else{return(mean(end)/mean(start))}
}
c_start = filter(corpus,!is.na(year),artist %in% c$artist,year <= year_end) %>% group_by(artist) %>% slice_head(n=25)%>% measure_lexicons()
c_end = filter(corpus,!is.na(year),artist %in% c$artist,year <= year_end) %>% group_by(artist) %>%
slice_tail(n=25) %>% measure_lexicons()
c_start_end = left_join(c_start,c_end,by="artist",suffix = c("_start","_end"))
c = left_join(c,c_start_end,by="artist")
Variable = c("diversity","mean","profanity","negative","positive","verlan","je","french","sexe","hate","sexism")
diff = data.frame(Variable)
difference = (100*(sapply(diff$Variable,FUN = diff_start_end,df=c)-1)) %>% round()
diff["Différence"] = difference %>% paste("%")
diff["Différence standardisée"] = sapply(diff$Variable,FUN = diff_start_end,df=c,scaled=TRUE) %>% round(2)
diff["Fréquence de chute"] = (100*sapply(diff$Variable,FUN = diff_start_end,df=c,prop=TRUE))%>% round() %>% paste("%")
diff["p-value"] = sapply(diff$Variable,FUN = diff_start_end,df=c,p=TRUE)
row.names(diff) = Variable
diff$Variable = c("Diversité lexicale sur 10 000 mots","Longueur moyenne des mots","Fréquences des insultes","Fréquences des mots négatifs","Fréquences des mots positifs","Fréquence du verlan",'Fréquence du "je"',"Part des mots dans le dictionnaire","Fréquence des mots sexuels","Fréquence des discours sexistes","Fréquence des discours haineux")
diff
c_start$sexism
get_complexity = function(text,n_words="none",return_mean=TRUE,tail=FALSE){
words = tokenize_words(str_replace_all(text,"'|’"," "),simplify = TRUE)
if(n_words == "none"){n_words = length(words)}
if(tail){words = tail(words, n_words)
}else{words = words[1:n_words]}
if(return_mean){
return(c(mean(nchar(words),na.rm=T),length(unique(words))))
}else{return(length(unique(words)))}
}
measure_lexicons = function(df){
return(df %>% summarise(
birthdate_artist = mean(birthdate_artist),
age_artist = mean(age_artist),
profanity = sum(n_profanity),
negative = sum(n_negative),
positive = sum(n_positive),
verlan = sum(n_verlan),
onomatopee = sum(n_onomatopee),
je = sum(n_je),
french = sum(n_french_words),
sexe = sum(n_sexe),
argot = sum(n_argot),
hate = weighted.mean(hate,n_lines),
sexism = weighted.mean(sexism,n_lines),
n_words =sum(n_words))%>%
mutate(profanity = profanity/n_words,
negative = negative/n_words,
positive = positive/n_words,
positivity_ratio = positive/negative,
verlan = verlan/n_words,
onomatopee = onomatopee/n_words,
je = je/n_words,
sexe = sexe/n_words,
argot = argot/n_words,
french = french/n_words)
)}
c = filter(corpus,!is.na(year),year <= year_end) %>% group_by(artist) %>%
summarise(n_words = sum(n_words),lyrics = paste(lyrics,collapse="\n"),
date_start = min(year,na.rm=T),date_end = max(year,na.rm=T)
)
c[c("mean_start","diversity_start")] = do.call(rbind, lapply(c$lyrics,get_complexity,n_words=10000))
c[c("mean_start","diversity_start")] = do.call(rbind, lapply(c$lyrics,get_complexity,n_words=10000))
c[c("mean_end","diversity_end")] = do.call(rbind, lapply(c$lyrics,get_complexity,n_words=10000,tail=TRUE))
plot_start_end = function(df,var,name){
var1 = paste(var,"start",sep="_")
var2 = paste(var,"end",sep="_")
df_reshaped = gather(df[c(var1,var2)],"Période","value")
df_reshaped$Période[df_reshaped$Période==var1] ="Début de carrière"
df_reshaped$Période[df_reshaped$Période==var2] ="Fin de carrière"
ggplot(df_reshaped,aes(value,fill=Période)) +
geom_density(alpha=.5) +
xlab(name) +  ylab("Densité")
}
diff_start_end = function(var,df, scaled= FALSE,prop=FALSE,p=FALSE){
var1 = paste(var,"start",sep="_")
var2 = paste(var,"end",sep="_")
start = unlist(df[var1])
end = unlist(df[var2])
if(p){return(t.test(start,end)$p.value %>% format.pval(digits=2,eps = .001))
}else if(prop){
return(mean(end < start))
}else if(scaled){
return((mean(end)-mean(start))/sd(c(start,end)))
}else{return(mean(end)/mean(start))}
}
c_start = filter(corpus,!is.na(year),artist %in% c$artist,year <= year_end) %>% group_by(artist) %>% slice_head(n=25)%>% measure_lexicons()
c_end = filter(corpus,!is.na(year),artist %in% c$artist,year <= year_end) %>% group_by(artist) %>%
slice_tail(n=25) %>% measure_lexicons()
c_start_end = left_join(c_start,c_end,by="artist",suffix = c("_start","_end"))
c = left_join(c,c_start_end,by="artist")
Variable = c("diversity","mean","profanity","negative","positive","verlan","je","french","sexe","hate","sexism")
diff = data.frame(Variable)
difference = (100*(sapply(diff$Variable,FUN = diff_start_end,df=c)-1)) %>% round()
diff["Différence"] = difference %>% paste("%")
diff["Différence standardisée"] = sapply(diff$Variable,FUN = diff_start_end,df=c,scaled=TRUE) %>% round(2)
diff["Fréquence de chute"] = (100*sapply(diff$Variable,FUN = diff_start_end,df=c,prop=TRUE))%>% round() %>% paste("%")
diff["p-value"] = sapply(diff$Variable,FUN = diff_start_end,df=c,p=TRUE)
row.names(diff) = Variable
diff$Variable = c("Diversité lexicale sur 10 000 mots","Longueur moyenne des mots","Fréquences des insultes","Fréquences des mots négatifs","Fréquences des mots positifs","Fréquence du verlan",'Fréquence du "je"',"Part des mots dans le dictionnaire","Fréquence des mots sexuels","Fréquence des discours sexistes","Fréquence des discours haineux")
diff
year_end
nrow(corpus)
year_end = 2024
c = filter(corpus,!is.na(year),year <= year_end) %>% group_by(artist) %>%
summarise(n_words = sum(n_words),lyrics = paste(lyrics,collapse="\n"),
date_start = min(year,na.rm=T),date_end = max(year,na.rm=T)
)
c = filter(c,n_words > 30000,c$date_end-c$date_start > 4)
c[c("mean_start","diversity_start")] = do.call(rbind, lapply(c$lyrics,get_complexity,n_words=10000))
c[c("mean_end","diversity_end")] = do.call(rbind, lapply(c$lyrics,get_complexity,n_words=10000,tail=TRUE))
c[c("mean_end","diversity_end")] = do.call(rbind, lapply(c$lyrics,get_complexity,n_words=10000,tail=TRUE))
plot_start_end = function(df,var,name){
var1 = paste(var,"start",sep="_")
var2 = paste(var,"end",sep="_")
df_reshaped = gather(df[c(var1,var2)],"Période","value")
df_reshaped$Période[df_reshaped$Période==var1] ="Début de carrière"
df_reshaped$Période[df_reshaped$Période==var2] ="Fin de carrière"
ggplot(df_reshaped,aes(value,fill=Période)) +
geom_density(alpha=.5) +
xlab(name) +  ylab("Densité")
}
diff_start_end = function(var,df, scaled= FALSE,prop=FALSE,p=FALSE){
var1 = paste(var,"start",sep="_")
var2 = paste(var,"end",sep="_")
start = unlist(df[var1])
end = unlist(df[var2])
if(p){return(t.test(start,end)$p.value %>% format.pval(digits=2,eps = .001))
}else if(prop){
return(mean(end < start))
}else if(scaled){
return((mean(end)-mean(start))/sd(c(start,end)))
}else{return(mean(end)/mean(start))}
}
c_start = filter(corpus,!is.na(year),artist %in% c$artist,year <= year_end) %>% group_by(artist) %>% slice_head(n=25)%>% measure_lexicons()
c_end = filter(corpus,!is.na(year),artist %in% c$artist,year <= year_end) %>% group_by(artist) %>%
slice_tail(n=25) %>% measure_lexicons()
c_start_end = left_join(c_start,c_end,by="artist",suffix = c("_start","_end"))
c = left_join(c,c_start_end,by="artist")
Variable = c("diversity","mean","profanity","negative","positive","verlan","je","french","sexe","hate","sexism")
diff = data.frame(Variable)
difference = (100*(sapply(diff$Variable,FUN = diff_start_end,df=c)-1)) %>% round()
diff["Différence"] = difference %>% paste("%")
diff["Différence standardisée"] = sapply(diff$Variable,FUN = diff_start_end,df=c,scaled=TRUE) %>% round(2)
diff["Fréquence de chute"] = (100*sapply(diff$Variable,FUN = diff_start_end,df=c,prop=TRUE))%>% round() %>% paste("%")
diff
year_end = 2014
c = filter(corpus,!is.na(year),year <= year_end) %>% group_by(artist) %>%
summarise(n_words = sum(n_words),lyrics = paste(lyrics,collapse="\n"),
date_start = min(year,na.rm=T),date_end = max(year,na.rm=T)
)
c = filter(c,n_words > 30000,c$date_end-c$date_start > 4)
c[c("mean_start","diversity_start")] = do.call(rbind, lapply(c$lyrics,get_complexity,n_words=10000))
c[c("mean_start","diversity_start")] = do.call(rbind, lapply(c$lyrics,get_complexity,n_words=10000))
c[c("mean_end","diversity_end")] = do.call(rbind, lapply(c$lyrics,get_complexity,n_words=10000,tail=TRUE))
c_start = filter(corpus,!is.na(year),artist %in% c$artist,year <= year_end) %>% group_by(artist) %>% slice_head(n=25)%>% measure_lexicons()
c_end = filter(corpus,!is.na(year),artist %in% c$artist,year <= year_end) %>% group_by(artist) %>%
slice_tail(n=25) %>% measure_lexicons()
c_start_end = left_join(c_start,c_end,by="artist",suffix = c("_start","_end"))
c = left_join(c,c_start_end,by="artist")
Variable = c("diversity","mean","profanity","negative","positive","verlan","je","french")
difference_before_2014 = (100*(sapply(Variable,FUN = diff_start_end,df=c)-1)) %>% round()
difference_before_2014
Variable = c("diversity","mean","profanity","negative","positive","verlan","je","french","sexism","hate")
difference_before_2014 = (100*(sapply(Variable,FUN = diff_start_end,df=c)-1)) %>% round()
difference_before_2014
(100*(sapply(Variable,FUN = diff_start_end,df=c)-1)) %>% round()
shiny::runApp()
input = list()
input$resolution="Année"
base=read.csv("base_presse_annees_nyt.csv",encoding = "UTF-8",sep = ",")
base
runApp()
runApp()
runApp()
runApp()
input
mot = "comrade"
period = 1900:2000
period = 1900:2000
if(input$resolution=="Année"){base=read.csv("base_presse_annees_nyt.csv",encoding = "UTF-8",sep = ",")}
base
read.csv("base_presse_mois_nyt.csv",encoding = "UTF-8",sep = ",")
read.csv("base_presse_mois_nyt.csv",encoding = "UTF-8",sep = ",") %>% tail()
input$beginning = 1900
input$end = 2000
base=base[base$annee>=input$beginning & base$annee<=input$end,]
period = input$beginning:input$end
library(crul)
mots = c("comrade")
for(mot in mots){
reqlist = list()
end_of_month = c(31,28,31,30,31,30,31,31,30,31,30,31)
months = c("01","02","03","04","05","06","07","08","09","10","11","12")
for(i in 1:length(period)){
if(input$resolution=="Année"){reqlist[[i]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",period[i],'-12-31&query=%22',mot,'%22&sort=best&startDate=',period[i],"-01-01&types=article"))$get()}
if(input$resolution=="Mois"){
for(month in 1:12){
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",period[i],'-',months[month],'-',end_of_month[month],'&query=%22',mot,'%22&sort=best&startDate=',period[i],'-',months[month],'-',"01&types=article"))$get()}
}
}
responses <- AsyncQueue$new(.list = reqlist,bucket_size=30,sleep=0)
responses$request()
if(input$resolution=="Année"){result = data.frame(date=period,count=NA)}
if(input$resolution=="Mois"){result = data.frame(annee = rep(period,each=12),mois= rep(months,length(period)),count = NA)
result$date = paste(result$annee,result$mois,sep="/")}
z = vector()
for(i in 1:length(reqlist)){
count = str_split(responses$responses()[[i]]$parse(),'totalCount":')[[1]][2]
result[i,"count"] = str_split(count,",")[[1]][1]
result[i,"url"] = reqlist[[i]]$url
}
#return(result)}
#result = nyt_scraper(period)
row.names(result) = result$date
result$count = as.integer(result$count)
for(b in 1:2){
z = which(is.na(result$count))
zz  =which(as.logical((result$count==0)*c(0,result$count[0:(nrow(result)-1)])>5))
zzz = which(as.logical((result$count>3*c(result$count[1],result$count[0:(nrow(result)-1)]))*(result$count>3*c(result$count[2:(nrow(result))],result$count[nrow(result)]))))
argmax = which.max(result$count)
if((!argmax %in% zzz) & max(result$count,na.rm = T) > 3*max(result$count[-argmax],na.rm = T)){zzz = c(zzz,argmax)}
if(length(z)+length(zz)+length(zzz)>0){
reqlist = list()
for(i in z){reqlist[[length(reqlist)+1]] = HttpRequest$new(url = result$url[i])$get()}
for(i in c(zz,zzz)){
if(input$resolution=="Année"){
month = sample(3:9,1)
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",period[i],months[month],end_of_month[month],'&query=',mot,'&sort=best&startDate=',period[i],"0101&types=article"))$get()
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",period[i],'1231&query=',mot,'&sort=best&startDate=',period[i],months[month]+1,"01&types=article"))$get()
}
if(input$resolution=="Mois"){
day = sample(10:20,1)
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",result$annee[i],result$mois[i],day,'&query=',mot,'&sort=best&startDate=',result$annee[i],result$mois[i],"01&types=article"))$get()
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",result$annee[i],result$mois[i],end_of_month[as.integer(result$mois[i])],'&query=',mot,'&sort=best&startDate=',result$annee[i],result$mois[i],day+1,"&types=article"))$get()
}
}
responses <- AsyncQueue$new(.list = reqlist,bucket_size=20,sleep=0)
responses$request()
print("b")
r = vector()
for(i in 1:length(responses$responses())){
count = str_split(responses$responses()[[i]]$parse(),'totalCount":')[[1]][2]
r[i] = str_split(count,",")[[1]][1]
}
r= as.integer(r)
#result2 = nyt_scraper(period[z])
result[z,"count"] = as.integer(r[1:length(z)])
result[c(zz,zzz),"count"] = as.integer(r[(length(z)+1):length(r)][c(T,F)])+as.integer(r[(length(z)+1):length(r)][c(F,T)])##Sum every two
}
}
result$count=as.integer(result$count)
if(input$resolution=="Année"){result$date=as.integer(result$date)}
result=left_join(result,base[c("date","base")],by="date")
result$ratio=result$count/result$base
result$ratio[result$ratio>2] = NA
result$mot=mot
if(mot==mots[1]){tableau=result}
else{tableau=rbind(tableau,result)}
}
end_of_month = c(31,28,31,30,31,30,31,31,30,31,30,31)
months = c("01","02","03","04","05","06","07","08","09","10","11","12")
for(i in 1:length(period)){
if(input$resolution=="Année"){reqlist[[i]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",period[i],'-12-31&query=%22',mot,'%22&sort=best&startDate=',period[i],"-01-01&types=article"))$get()}
if(input$resolution=="Mois"){
for(month in 1:12){
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",period[i],'-',months[month],'-',end_of_month[month],'&query=%22',mot,'%22&sort=best&startDate=',period[i],'-',months[month],'-',"01&types=article"))$get()}
}
}
responses <- AsyncQueue$new(.list = reqlist,bucket_size=30,sleep=0)
responses$request()
if(input$resolution=="Année"){result = data.frame(date=period,count=NA)}
result
result$date = paste(result$annee,result$mois,sep="/")}
result$date = paste(result$annee,result$mois,sep="/")}
result$date = paste(result$annee,result$mois,sep="/")
if(input$resolution=="Année"){result = data.frame(date=period,count=NA)}
z = vector()
for(i in 1:length(reqlist)){
count = str_split(responses$responses()[[i]]$parse(),'totalCount":')[[1]][2]
result[i,"count"] = str_split(count,",")[[1]][1]
result[i,"url"] = reqlist[[i]]$url
}
result$count
#return(result)}
#result = nyt_scraper(period)
row.names(result) = result$date
result$count = as.integer(result$count)
for(b in 1:2){
z = which(is.na(result$count))
zz  =which(as.logical((result$count==0)*c(0,result$count[0:(nrow(result)-1)])>5))
zzz = which(as.logical((result$count>3*c(result$count[1],result$count[0:(nrow(result)-1)]))*(result$count>3*c(result$count[2:(nrow(result))],result$count[nrow(result)]))))
argmax = which.max(result$count)
if((!argmax %in% zzz) & max(result$count,na.rm = T) > 3*max(result$count[-argmax],na.rm = T)){zzz = c(zzz,argmax)}
if(length(z)+length(zz)+length(zzz)>0){
reqlist = list()
for(i in z){reqlist[[length(reqlist)+1]] = HttpRequest$new(url = result$url[i])$get()}
for(i in c(zz,zzz)){
if(input$resolution=="Année"){
month = sample(3:9,1)
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",period[i],months[month],end_of_month[month],'&query=',mot,'&sort=best&startDate=',period[i],"0101&types=article"))$get()
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",period[i],'1231&query=',mot,'&sort=best&startDate=',period[i],months[month]+1,"01&types=article"))$get()
}
if(input$resolution=="Mois"){
day = sample(10:20,1)
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",result$annee[i],result$mois[i],day,'&query=',mot,'&sort=best&startDate=',result$annee[i],result$mois[i],"01&types=article"))$get()
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",result$annee[i],result$mois[i],end_of_month[as.integer(result$mois[i])],'&query=',mot,'&sort=best&startDate=',result$annee[i],result$mois[i],day+1,"&types=article"))$get()
}
}
responses <- AsyncQueue$new(.list = reqlist,bucket_size=20,sleep=0)
responses$request()
print("b")
r = vector()
for(i in 1:length(responses$responses())){
count = str_split(responses$responses()[[i]]$parse(),'totalCount":')[[1]][2]
r[i] = str_split(count,",")[[1]][1]
}
r= as.integer(r)
#result2 = nyt_scraper(period[z])
result[z,"count"] = as.integer(r[1:length(z)])
result[c(zz,zzz),"count"] = as.integer(r[(length(z)+1):length(r)][c(T,F)])+as.integer(r[(length(z)+1):length(r)][c(F,T)])##Sum every two
}
}
z = which(is.na(result$count))
zz  =which(as.logical((result$count==0)*c(0,result$count[0:(nrow(result)-1)])>5))
zzz = which(as.logical((result$count>3*c(result$count[1],result$count[0:(nrow(result)-1)]))*(result$count>3*c(result$count[2:(nrow(result))],result$count[nrow(result)]))))
argmax = which.max(result$count)
if((!argmax %in% zzz) & max(result$count,na.rm = T) > 3*max(result$count[-argmax],na.rm = T)){zzz = c(zzz,argmax)}
if(length(z)+length(zz)+length(zzz)>0){
reqlist = list()
for(i in z){reqlist[[length(reqlist)+1]] = HttpRequest$new(url = result$url[i])$get()}
for(i in c(zz,zzz)){
if(input$resolution=="Année"){
month = sample(3:9,1)
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",period[i],months[month],end_of_month[month],'&query=',mot,'&sort=best&startDate=',period[i],"0101&types=article"))$get()
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",period[i],'1231&query=',mot,'&sort=best&startDate=',period[i],months[month]+1,"01&types=article"))$get()
}
if(input$resolution=="Mois"){
day = sample(10:20,1)
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",result$annee[i],result$mois[i],day,'&query=',mot,'&sort=best&startDate=',result$annee[i],result$mois[i],"01&types=article"))$get()
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",result$annee[i],result$mois[i],end_of_month[as.integer(result$mois[i])],'&query=',mot,'&sort=best&startDate=',result$annee[i],result$mois[i],day+1,"&types=article"))$get()
}
}
responses <- AsyncQueue$new(.list = reqlist,bucket_size=20,sleep=0)
responses$request()
print("b")
r = vector()
for(i in 1:length(responses$responses())){
count = str_split(responses$responses()[[i]]$parse(),'totalCount":')[[1]][2]
r[i] = str_split(count,",")[[1]][1]
}
r= as.integer(r)
#result2 = nyt_scraper(period[z])
result[z,"count"] = as.integer(r[1:length(z)])
result[c(zz,zzz),"count"] = as.integer(r[(length(z)+1):length(r)][c(T,F)])+as.integer(r[(length(z)+1):length(r)][c(F,T)])##Sum every two
}
months
length(z)+length(zz)+length(zzz)
reqlist = list()
for(i in z){reqlist[[length(reqlist)+1]] = HttpRequest$new(url = result$url[i])$get()}
for(i in c(zz,zzz)){
if(input$resolution=="Année"){
month = sample(3:9,1)
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",period[i],months[month],end_of_month[month],'&query=',mot,'&sort=best&startDate=',period[i],"0101&types=article"))$get()
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",period[i],'1231&query=',mot,'&sort=best&startDate=',period[i],months[month]+1,"01&types=article"))$get()
}
if(input$resolution=="Mois"){
day = sample(10:20,1)
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",result$annee[i],result$mois[i],day,'&query=',mot,'&sort=best&startDate=',result$annee[i],result$mois[i],"01&types=article"))$get()
reqlist[[length(reqlist)+1]] = HttpRequest$new(url = str_c("https://www.nytimes.com/search?dropmab=false&endDate=",result$annee[i],result$mois[i],end_of_month[as.integer(result$mois[i])],'&query=',mot,'&sort=best&startDate=',result$annee[i],result$mois[i],day+1,"&types=article"))$get()
}
}
for(i in z){reqlist[[length(reqlist)+1]] = HttpRequest$new(url = result$url[i])$get()}
reqlist = list()
for(i in z){reqlist[[length(reqlist)+1]] = HttpRequest$new(url = result$url[i])$get()}
runApp()
shiny::runApp()
runApp()
runApp()
input = list()
input$doc_type = 30
input$mot = "coucou"
mots = str_split(input$mot,"&")[[1]]
source("~/code/docker_gallicagram/gallicagram/ngramize.R")
runApp()
runApp()
url_base = "https://shiny.ens-paris-saclay.fr/guni" #If you are not on the gallicagram server
ngramize()
ngramize(input)
mot = "coucou"
df = read.csv(glue("{url_base}/query?corpus=lemonde_rubriques&mot={URLencode(mot)}&from={from}&to={to}&rubrique={input$rubrique_lemonde}"))
input$from = 1950
from = 1950
to = 2000
df = read.csv(glue("{url_base}/query?corpus=lemonde_rubriques&mot={URLencode(mot)}&from={from}&to={to}&rubrique={input$rubrique_lemonde}"))
glue("{url_base}/query?corpus=lemonde_rubriques&mot={URLencode(mot)}&from={from}&to={to}&rubrique={input$rubrique_lemonde}")
url_base
URLencode(mot)
input$rubrique_lemonde
input$rubrique_lemonde = FALSE
glue("{url_base}/query?corpus=lemonde_rubriques&mot={URLencode(mot)}&from={from}&to={to}&rubrique={input$rubrique_lemonde}")
source("~/code/docker_gallicagram/gallicagram/ngramize.R")
runApp()
source("~/code/docker_gallicagram/gallicagram/ngramize.R")
runApp()
runApp()
input
runApp()
rubriques_lemonde = c("international","culture","politique","société","sport","science/technologie","inclassable")
input
input$rubrique_lemonde = rubriques_lemonde
df = read.csv(glue("{url_base}/query?corpus=lemonde_rubriques&mot={URLencode(mot)}&from={from}&to={to}&rubrique={paste(input$rubrique_lemonde,collapse="+")}&by_rubrique={str_to_title(tolower(input$lemonde_by_rubrique))}"))
input$rubrique_lemonde
paste(input$rubrique_lemonde,collapse="+")
input$rubrique_lemonde
paste(input$rubrique_lemonde[1:5],collapse="+")
str_to_title(tolower(input$lemonde_by_rubrique))
input$lemonde_by_rubrique = FALSE
df = read.csv(glue("{url_base}/query?corpus=lemonde_rubriques&mot={URLencode(mot)}&from={from}&to={to}&rubrique={paste(input$rubrique_lemonde,collapse="+")}&by_rubrique={str_to_title(tolower(input$lemonde_by_rubrique))}"))
paste(input$rubrique_lemonde,collapse="+")
URLencode(mot)
glue("{url_base}/query?corpus=lemonde_rubriques&mot={URLencode(mot)}&from={from}&to={to}&rubrique={paste(input$rubrique_lemonde,collapse="+")}")
glue("{url_base}/query?corpus=lemonde_rubriques&mot={URLencode(mot)}&from={from}&to={to}&rubrique=")
paste(input$rubrique_lemonde,collapse="+")
glue("{url_base}/query?corpus=lemonde_rubriques&mot={URLencode(mot)}&from={from}&to={to}&rubrique={paste(input$rubrique_lemonde[1:4],collapse="+")}")
glue("{url_base}/query?corpus=lemonde_rubriques&mot={URLencode(mot)}&from={from}&to={to}&rubrique={paste(input$rubrique_lemonde[1:4],collapse='+')}")
df = read.csv(glue("{url_base}/query?corpus=lemonde_rubriques&mot={URLencode(mot)}&from={from}&to={to}&rubrique={paste(input$rubrique_lemonde,collapse='+')}&by_rubrique={str_to_title(tolower(input$lemonde_by_rubrique))}"))
rubriques_lemonde = c("international","culture","politique","société","sport","science,technologie","inclassable")
output$rubrique_lemonde <- renderUI({pickerInput("rubrique_lemonde","Rubrique",choices = rubriques_lemonde, multiple=T,selected=rubriques_lemonde,options = list(`actions-box` = TRUE,`live-search`=TRUE))})
runApp()
runApp()
runApp()
input$resolution = "Année"
recode(input$resolution, "Année"="annee")
resolution <- recode(input$resolution, "Année"="annee","Mois"="mois")
runApp()
runApp()
tableau = read.csv("~/Downloads/")
tableau = read.csv("~/Downloads/data_pas_1986_1989Le Monde.csv")
tableau
loess = tableau$loess
base = tableau$base
tableau$ribbon_down = loess-1.96*sqrt(loess*(1-loess)/base)
z = which(tableau$ribbon_down<0)
loess-1.96*sqrt(loess*(1-loess)/base)
loess = tableau$ratio
loess = tableau$loess
base = tableau$base
tableau$ribbon_down = loess-1.96*sqrt(loess*(1-loess)/base)
tableau$base
loess
loess = tableau$ratio
loess
base = tableau$base
tableau$ribbon_down = loess-1.96*sqrt(loess*(1-loess)/base)
z = which(tableau$ribbon_down<0)
tableau$ribbon_down[z] = 0
tableau$ribbon_up = loess+1.96*sqrt(loess*(1-loess)/base)
z = which(loess==0)
tableau$ribbon_up[z] = 3/base[z]
tableau$ribbon_up[is.na(tableau$ribbon_up)] <- max(tableau$ribbon_up,na.rm=T)
tableau$ribbon_down[is.na(tableau$ribbon_down)] <- 0
tableau$ribbon_up[tableau$ribbon_up>1.1*max(loess,na.rm=T)] = max(loess,na.rm=T)*1.1
plot = plot_ly(tableau, x=~date,y=~loess,color =~mot,type='scatter',mode='lines+markers',line = list(shape = "spline"),linetype = linetype,customdata=tableau$url,colors=customPalette,legendgroup=~mot,text=~hovers,hoverinfo="text",connectgaps = FALSE)
plot = plot_ly(tableau, x=~date,y=~loess,color =~mot,type='scatter',mode='lines+markers',line = list(shape = "spline"),customdata=tableau$url,colors=customPalette,legendgroup=~mot,text=~hovers,hoverinfo="text",connectgaps = FALSE)
plot = plot_ly(tableau, x=~date,y=~loess,color =~mot,type='scatter',mode='lines+markers',line = list(shape = "spline"),customdata=tableau$url,legendgroup=~mot,text=~hovers,hoverinfo="text",connectgaps = FALSE)
plot=plot%>%add_ribbons(data=tableau,x=~date,ymin=~ribbon_down,ymax=~ribbon_up,legendgroup=~mot,fillcolor=~mot,showlegend=F,opacity=.2)
plot
plot = plot_ly(tableau, x=~date,y=~loess,color =~mot,type='scatter',mode='lines+markers',line = list(shape = "spline"),customdata=tableau$url,legendgroup=~mot,text,connectgaps = FALSE)
plot
plot_ly(tableau, x=~date,y=~loess,color =~mot,type='scatter',mode='lines+markers',line = list(shape = "spline"),customdata=tableau$url,legendgroup=~mot,connectgaps = FALSE)
plot = plot_ly(tableau, x=~date,y=~loess,color =~mot,type='scatter',mode='lines+markers',line = list(shape = "spline"),customdata=tableau$url,legendgroup=~mot,connectgaps = FALSE)
paste(tableau$annee,tableau$mois,"01",sep="/")
as.Date(paste(tableau$annee,tableau$mois,"01",sep="/")))
as.Date(paste(tableau$annee,tableau$mois,"01",sep="/"))
runApp()
#!identical(input$rev_persee,"all")
z = tableau$mois < 10
str_c("0",tableau$mois[z])
tableau$mois[z] = str_c("0",tableau$mois[z])
tableau$mois
runApp()
runApp()
"mois" %in% colnames(tableau)
colnames(tableau)
#!identical(input$rev_persee,"all")
if("mois" %in% colnames(tableau)){z = tableau$mois < 10
"mois" in tableau$mois[z] = str_c("0",tableau$mois[z])
runApp()
runApp()
runApp()
runApp()
source("~/code/docker_gallicagram/gallicagram/ngramize.R")
runApp()
runApp()
